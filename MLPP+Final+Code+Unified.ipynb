{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLPP+Final+Code+Unified.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nm3ZxW5cxyjh"
      },
      "source": [
        "# Stan Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt3Eg6cBnCqh"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cmdstanpy\n",
        "cmdstanpy.install_cmdstan()\n",
        "from cmdstanpy import cmdstan_path, CmdStanModel\n",
        "from sklearn.manifold import TSNE\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "!gdown https://drive.google.com/uc?id=1G-FORBywVm4dt7XqlQaf9s2dlvlmCt7f&export=download #downloading data json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uOSZznT962n"
      },
      "source": [
        "#Some necessary files\n",
        "!gdown https://drive.google.com/uc?id=1dwJMGK1wjG6539qt3-8LXCgKrbUlNaev&export=download\n",
        "!gdown https://drive.google.com/uc?id=14nSL_wJHt97PmtI92-QQalpNGYwzBy6V&export=download\n",
        "!gdown https://drive.google.com/uc?id=1q4JXp1HsazO_4vgl4hgiPC2jWVl9wHoE&export=download\n",
        "!gdown https://drive.google.com/uc?id=16qkjRKtDGzolywt1SNS6OsnR7rNQqdjn&export=download\n",
        "\n",
        "word_list=pickle.load(open(\"word_list.pkl\", \"rb\"))\n",
        "X=pickle.load(open(\"embedding_matrix.pkl\", \"rb\"))\n",
        "\n",
        "word_pair = pickle.load(open(\"word_pairs.pkl\", \"rb\"))\n",
        "embd_pairs = pickle.load(open(\"pairs.pkl\", \"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbKLBKc3lAIg"
      },
      "source": [
        "**Important**: If you want to run a model from scratch, change run_model_x to True, the stan files will be downloaded and inference from scratch will be performed. Else it will download the learnt parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg8JiEEglExE"
      },
      "source": [
        "run_model_1 = True\n",
        "run_model_2 = False\n",
        "run_model_3 = True #takes about 30 mins to run\n",
        "\n",
        "if run_model_1 :\n",
        "    !gdown https://drive.google.com/uc?id=10vXwK-G5TWrU7N67kpNRoDHkCUL4x5XT&export=download\n",
        "    stan = 'model1.stan'\n",
        "    model = CmdStanModel(stan_file=stan)\n",
        "    model.name\n",
        "    model.stan_file\n",
        "    model.exe_file\n",
        "    model.code()\n",
        "\n",
        "    data = 'data.json'\n",
        "    variational_vb = model.variational(data=data, output_dir='.',save_diagnostics=True)\n",
        "\n",
        "    a=[]\n",
        "    for i in range(1,101):\n",
        "        a.append(variational_vb.variational_params_dict['a.'+str(i)])\n",
        "    np.save('a.npy',a)\n",
        "\n",
        "else:\n",
        "    !gdown https://drive.google.com/uc?id=1hSCN73ruVDKRRKl0suz4J5W_ECZN1l3b&export=download\n",
        "a=np.load('a.npy')\n",
        "    \n",
        "\n",
        "if run_model_3 :\n",
        "    !gdown https://drive.google.com/uc?id=1zz2LvKkOud7TrttjNnI4M9051ZjCgmEP&export=download\n",
        "    stan = 'model3.stan'\n",
        "    model = CmdStanModel(stan_file=stan)\n",
        "    model.name\n",
        "    model.stan_file\n",
        "    model.exe_file\n",
        "    model.code()\n",
        "\n",
        "    data = 'data.json'\n",
        "    variational_vb = model.variational(data=data, output_dir='.',save_diagnostics=True)\n",
        "\n",
        "    a = np.zeros((100,100))\n",
        "    for i in range(1,101):\n",
        "        for j in range(1,101):\n",
        "            a[i-1,j-1]=variational_vb.variational_params_dict['a.'+str(i)+'.'+str(j)]\n",
        "    np.save('a_model3.npy',a)\n",
        "\n",
        "else:\n",
        "    !gdown https://drive.google.com/uc?id=1lSGFlhjSLK_vopHCH8dGCiDxEjbqX7IX&export=download\n",
        "A=np.load('a_model3.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsZ2vKhwyryh"
      },
      "source": [
        "#Threshold based classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Zx-ouK9zcGB"
      },
      "source": [
        "X= embd_pairs[:,:200]\n",
        "y= embd_pairs[:,200]\n",
        "A=A.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQHcdWs80JJ_"
      },
      "source": [
        "# GloVe\n",
        "y_ = (X[:,0:int(X.shape[1]/2)]*X[:,int(X.shape[1]/2):]).sum(axis=1)/(np.linalg.norm(X[:,0:int(X.shape[1]/2)],axis=1)*np.linalg.norm(X[:,int(X.shape[1]/2):],axis=1))\n",
        "y_ = (y_ >=0).astype(int)\n",
        "print('Glove gives an accuracy of', np.sum(y==y_)/len(y))\n",
        "\n",
        "#Model 1\n",
        "a_double = np.expand_dims(np.hstack((a,a)),axis=1).T\n",
        "X_new = X*a_double\n",
        "y__ = (X_new[:,0:int(X.shape[1]/2)]*X_new[:,int(X.shape[1]/2):]).sum(axis=1)/(np.linalg.norm(X_new[:,0:int(X.shape[1]/2)],axis=1)*np.linalg.norm(X_new[:,int(X.shape[1]/2):],axis=1))\n",
        "y__ = (y__ >=0).astype(int)\n",
        "print('Model 1 gives an accuracy of', np.sum(y==y__)/len(y))\n",
        "\n",
        "# Model 3\n",
        "temp1= X[:,:100]\n",
        "temp2 = X[:,100:]\n",
        "X_new = np.hstack((np.matmul(temp1,A),np.matmul(temp2,A)))\n",
        "y__ = (X_new[:,0:int(X.shape[1]/2)]*X_new[:,int(X.shape[1]/2):]).sum(axis=1)/(np.linalg.norm(X_new[:,0:int(X.shape[1]/2)],axis=1)*np.linalg.norm(X_new[:,int(X.shape[1]/2):],axis=1))\n",
        "y__ = (y__ >=0).astype(int)\n",
        "print('Model 3 gives an accuracy of', np.sum(y==y__)/len(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHX52VHzsSM7"
      },
      "source": [
        "#t-sne"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxP3ZU7LwVRb"
      },
      "source": [
        "run_tsne = False # download already run embeddings if False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYOK2kgYsvMz"
      },
      "source": [
        "def transform_model1(W):\n",
        "    a=np.load('a.npy') #this will be column vector\n",
        "    W_new = W*np.expand_dims(a,axis=1).T\n",
        "    return W_new\n",
        "\n",
        "def transfrom_model2(W):\n",
        "    a=np.load() #this will be column vector\n",
        "    s=np.load()\n",
        "    \n",
        "    W_a = W*np.expand_dims(a,axis=1).T\n",
        "    W_s = W*np.expand_dims(s,axis=1).T\n",
        "    \n",
        "    return W_a,W_s\n",
        "\n",
        "def transform_model3(W):\n",
        "    A= np.load('a_model3.npy')\n",
        "    A=A.T\n",
        "    return np.matmul(W,A)\n",
        "\n",
        "\n",
        "\n",
        "if run_tsne:\n",
        "    np.save('glove_X_embedding.npy',TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(X))\n",
        "    np.save('model1_X_embedding.npy',TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(transform_model1(X)))\n",
        "    np.save('model3_X_embedding.npy',TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(transform_model1(X)))\n",
        "else:\n",
        "    !gdown https://drive.google.com/uc?id=12a_310_fv73muAfIabFR3vK63YG84PhX&export=download\n",
        "    !gdown https://drive.google.com/uc?id=1sWX_nyRI66DLWIbPz4WbCeLQhEsY1uif&export=download\n",
        "    !gdown https://drive.google.com/uc?id=1RMo2q_lETRqjZlEJetJXZU3G3GV-JZbn&export=download\n",
        "\n",
        "X_embedded_1 = np.load('model1_X_embedding.npy')\n",
        "X_embedded_3 = np.load('model3_X_embedding.npy')\n",
        "X_embedded_glove = np.load('glove_X_embedding.npy')\n",
        "\n",
        "X_embedded_list = [X_embedded_glove, X_embedded_1,X_embedded_3]\n",
        "\n",
        "indices =[4,6,9,13,17] #Indices of pairs to plot\n",
        "\n",
        "for X_embedded in X_embedded_list:\n",
        "\n",
        "    select_word_pairs = [word_pair[i][0] for i in indices]+ [word_pair[i][1] for i in indices]\n",
        "    select_word_indices = [word_list.index(word) for word in select_word_pairs]\n",
        "    select_word_embeddings = np.array([X_embedded[i,:] for i in select_word_indices])\n",
        "    \n",
        "    plt.scatter(select_word_embeddings[:,0],select_word_embeddings[:,1],linewidths=1,color='blue')\n",
        "    plt.grid()\n",
        "    plt.xlabel(\"PC1\",size=15)\n",
        "    plt.ylabel(\"PC2\",size=15)\n",
        "    plt.title(\"Word Embedding Space\",size=20)\n",
        "    \n",
        "    for i, word in enumerate(select_word_pairs):\n",
        "        plt.annotate(word,xy=(select_word_embeddings[i,0],select_word_embeddings[i,1]))\n",
        "    for i in range(select_word_embeddings.shape[0]):\n",
        "        plt.arrow(0,0,select_word_embeddings[i,0],select_word_embeddings[i,1])\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}